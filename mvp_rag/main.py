#!/usr/bin/env python3
"""
MVP RAG Healthcare AI Assistant Demo

This demonstrates a real RAG system using local AI tools:
- Ollama for LLM and embeddings
- Qdrant for vector storage
- Real semantic search and generation
"""

import sys
import time
from pathlib import Path

# Add current directory to path for imports
sys.path.append(str(Path(__file__).parent))

from core.rag_engine import RAGEngine
from utils.logger import get_logger

logger = get_logger("main")

def main():
    """Run the MVP RAG demo."""
    print("ğŸ¥ MVP RAG Healthcare AI Assistant Demo")
    print("=" * 60)
    print("ğŸš€ Real RAG with Local AI Tools: Ollama + Qdrant")
    print()
    
    # Initialize the RAG engine
    print("ğŸ”§ Initializing RAG Engine...")
    try:
        rag_engine = RAGEngine()
        print("âœ… RAG Engine initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize RAG Engine: {e}")
        print("Please ensure Ollama and Qdrant are running")
        return
    
    # Health check
    print("\nğŸ¥ Health Check:")
    health = rag_engine.health_check()
    for service, status in health.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"   {status_icon} {service}: {'Healthy' if status else 'Unhealthy'}")
    
    if not health["overall"]:
        print("\nâŒ System health check failed. Please check services.")
        return
    
    # System info
    print("\nğŸ“Š System Information:")
    system_info = rag_engine._get_system_info()
    print(f"   RAG Engine: {system_info['rag_engine']}")
    print(f"   LLM Model: {system_info['llm_model']}")
    print(f"   Embedding Model: {system_info['embedding_model']}")
    print(f"   Vector Store: {system_info['vector_store']}")
    
    # Demo queries
    demo_queries = [
        "What are the symptoms of diabetes?",
        "How do I check my blood pressure at home?",
        "What should I do if I have chest pain?",
        "How do I manage stress and anxiety?",
        "What are the benefits of regular exercise?"
    ]
    
    print(f"\nğŸ’¡ Demo Queries Available: {len(demo_queries)}")
    for i, query in enumerate(demo_queries, 1):
        print(f"   {i}. {query}")
    
    # Interactive demo
    print(f"\nğŸ­ Interactive Demo Mode")
    print("Type 'quit' to exit, 'demo' to run sample queries, or ask a health question.")
    print("Type 'health' to check system status.")
    
    while True:
        try:
            user_input = input("\nğŸ¥ Your health question: ").strip()
            
            if user_input.lower() == 'quit':
                print("ğŸ‘‹ Thanks for trying the MVP RAG Healthcare AI Assistant!")
                break
            
            elif user_input.lower() == 'demo':
                print("\nğŸ¬ Running sample queries...")
                for query in demo_queries[:3]:  # Show first 3
                    print(f"\n--- Query: {query} ---")
                    result = rag_engine.query(query)
                    print(f"Response: {result['response'][:200]}...")
                    print(f"Documents Retrieved: {result['metrics']['documents_retrieved']}")
                    print(f"Total Time: {result['metrics']['total_time_ms']}ms")
                continue
            
            elif user_input.lower() == 'health':
                print("\nğŸ¥ System Health Check:")
                health = rag_engine.health_check()
                for service, status in health.items():
                    status_icon = "âœ…" if status else "âŒ"
                    print(f"   {status_icon} {service}: {'Healthy' if status else 'Unhealthy'}")
                continue
            
            elif not user_input:
                continue
            
            # Process the user's health question
            print(f"\nğŸ” Processing: {user_input}")
            start_time = time.time()
            
            result = rag_engine.query(user_input)
            
            # Display results
            print(f"\nğŸ“ Response:")
            print(result['response'])
            
            print(f"\nğŸ“Š Performance Metrics:")
            print(f"   Total Time: {result['metrics']['total_time_ms']}ms")
            print(f"   Embedding Time: {result['metrics']['embedding_time_ms']}ms")
            print(f"   Search Time: {result['metrics']['search_time_ms']}ms")
            print(f"   Generation Time: {result['metrics']['generation_time_ms']}ms")
            print(f"   Documents Retrieved: {result['metrics']['documents_retrieved']}")
            print(f"   Average Similarity Score: {result['metrics']['average_similarity_score']}")
            
            # Show retrieved context
            if result['context']['retrieved_documents']:
                print(f"\nğŸ“š Retrieved Context:")
                print(f"   {result['context']['context_summary']}")
                
                # Show top document
                top_doc = result['context']['retrieved_documents'][0]
                print(f"\n   Top Document (Score: {top_doc['score']:.3f}):")
                print(f"   Source: {top_doc.get('source', 'Unknown')}")
                print(f"   Content: {top_doc['content'][:150]}...")
            
            # Show what this demonstrates
            print(f"\nğŸ’¡ What This Demonstrates:")
            print(f"   âœ… Real RAG with local AI tools")
            print(f"   âœ… Semantic search with embeddings")
            print(f"   âœ… Dynamic LLM responses")
            print(f"   âœ… Performance metrics and monitoring")
            
            # Show next steps
            print(f"\nğŸš€ Next Steps to Production:")
            print(f"   ğŸ”„ Replace Ollama with Azure OpenAI")
            print(f"   ğŸ”„ Replace Qdrant with Azure AI Search")
            print(f"   ğŸ”„ Add Content Safety and compliance")
            print(f"   ğŸ”„ Add agentic workflow and tools")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Demo interrupted. Thanks for trying!")
            break
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            print(f"\nâŒ Error: {e}")
            print("This demonstrates another limitation of the MVP - error handling.")
    
    # Final summary
    print(f"\nğŸ¯ Demo Complete!")
    print("This MVP shows a REAL RAG system working with local AI tools.")
    print("The production version will have:")
    print("   âœ… Azure OpenAI for enterprise LLM")
    print("   âœ… Azure AI Search for scalable vectors")
    print("   âœ… Content Safety for compliance")
    print("   âœ… Full observability and monitoring")

if __name__ == "__main__":
    main()
